{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wluJKvsB0Vnk",
        "outputId": "3431d2ba-1f1b-4a42-a0ac-44fec69c0829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,757 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,078 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,037 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,371 kB]\n",
            "Fetched 7,308 kB in 3s (2,739 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=109013abeac1a23c47bbd65b40b10ddeddbbc0f79b766aded5f9b55e473a00d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icZU2Agk1Gi2",
        "outputId": "aad669d8-bdaa-4e77-8230-808c562b3948"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "DQBdYOcs1O90"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/drive/MyDrive/Programación/PySpark/Titanic/titanic_train.csv\", header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eykp0ik1cFb",
        "outputId": "820b39cc-7571-466c-9a45-71f25bf442dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar el número de valores nulos en cada columna\n",
        "null_counts = [(col_name, df.where(F.col(col_name).isNull()).count()) for col_name in df.columns]\n",
        "\n",
        "# Imprimir el resultado\n",
        "for col_name, count in null_counts:\n",
        "    print(f\"Columna '{col_name}': {count} valores nulos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FhyzkEu9wBt",
        "outputId": "bfc0baec-2097-4ff3-93f8-854dbe96bc60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna 'PassengerId': 0 valores nulos\n",
            "Columna 'Survived': 0 valores nulos\n",
            "Columna 'Pclass': 0 valores nulos\n",
            "Columna 'Name': 0 valores nulos\n",
            "Columna 'Sex': 0 valores nulos\n",
            "Columna 'Age': 177 valores nulos\n",
            "Columna 'SibSp': 0 valores nulos\n",
            "Columna 'Parch': 0 valores nulos\n",
            "Columna 'Ticket': 0 valores nulos\n",
            "Columna 'Fare': 0 valores nulos\n",
            "Columna 'Cabin': 687 valores nulos\n",
            "Columna 'Embarked': 2 valores nulos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimina la columna 'Cabin' del DataFrame 'df'\n",
        "df = df.drop('Cabin', 'Name', 'PassengerID', 'Ticket', 'Parch', 'SibSp')"
      ],
      "metadata": {
        "id": "UjulP5LG937I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimina las filas con valores nulos solo en las columnas 'Age' y 'Embarked'\n",
        "df = df.dropna(subset=['Age', 'Embarked'])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDRqd_3i-aBR",
        "outputId": "e1fccbd3-dad1-4e68-c198-7ebf8dd51546"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-------+--------+\n",
            "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
            "+--------+------+------+----+-------+--------+\n",
            "|       0|     3|  male|22.0|   7.25|       S|\n",
            "|       1|     1|female|38.0|71.2833|       C|\n",
            "|       1|     3|female|26.0|  7.925|       S|\n",
            "|       1|     1|female|35.0|   53.1|       S|\n",
            "|       0|     3|  male|35.0|   8.05|       S|\n",
            "|       0|     1|  male|54.0|51.8625|       S|\n",
            "|       0|     3|  male| 2.0| 21.075|       S|\n",
            "|       1|     3|female|27.0|11.1333|       S|\n",
            "|       1|     2|female|14.0|30.0708|       C|\n",
            "|       1|     3|female| 4.0|   16.7|       S|\n",
            "|       1|     1|female|58.0|  26.55|       S|\n",
            "|       0|     3|  male|20.0|   8.05|       S|\n",
            "|       0|     3|  male|39.0| 31.275|       S|\n",
            "|       0|     3|female|14.0| 7.8542|       S|\n",
            "|       1|     2|female|55.0|   16.0|       S|\n",
            "|       0|     3|  male| 2.0| 29.125|       Q|\n",
            "|       0|     3|female|31.0|   18.0|       S|\n",
            "|       0|     2|  male|35.0|   26.0|       S|\n",
            "|       1|     2|  male|34.0|   13.0|       S|\n",
            "|       1|     3|female|15.0| 8.0292|       Q|\n",
            "+--------+------+------+----+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sex_indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
        "df = sex_indexer.fit(df).transform(df)\n",
        "\n",
        "# Crear StringIndexer para la columna Embarked\n",
        "embarked_indexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
        "df = embarked_indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "q9Hah20yD5pN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_values = df.select(\"EmbarkedIndex\").distinct()\n",
        "distinct_values.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2c26gLSNdNQ",
        "outputId": "d2f77982-effc-4b9b-c4cc-a46f6186cc4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|EmbarkedIndex|\n",
            "+-------------+\n",
            "|          0.0|\n",
            "|          1.0|\n",
            "|          2.0|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOzccXuxE9_D",
        "outputId": "34f97a22-880c-4c07-bde5-3a6349f829fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-------+--------+--------+-------------+\n",
            "|Survived|Pclass|   Sex| Age|   Fare|Embarked|SexIndex|EmbarkedIndex|\n",
            "+--------+------+------+----+-------+--------+--------+-------------+\n",
            "|       0|     3|  male|22.0|   7.25|       S|     0.0|          0.0|\n",
            "|       1|     1|female|38.0|71.2833|       C|     1.0|          1.0|\n",
            "|       1|     3|female|26.0|  7.925|       S|     1.0|          0.0|\n",
            "|       1|     1|female|35.0|   53.1|       S|     1.0|          0.0|\n",
            "|       0|     3|  male|35.0|   8.05|       S|     0.0|          0.0|\n",
            "+--------+------+------+----+-------+--------+--------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Sex', 'Embarked')"
      ],
      "metadata": {
        "id": "E9hv0EalFCjF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTbj2Hn1FL2L",
        "outputId": "896818d7-8fa8-442b-95ee-2e03290b0ce9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----+-------+--------+-------------+\n",
            "|Survived|Pclass| Age|   Fare|SexIndex|EmbarkedIndex|\n",
            "+--------+------+----+-------+--------+-------------+\n",
            "|       0|     3|22.0|   7.25|     0.0|          0.0|\n",
            "|       1|     1|38.0|71.2833|     1.0|          1.0|\n",
            "|       1|     3|26.0|  7.925|     1.0|          0.0|\n",
            "|       1|     1|35.0|   53.1|     1.0|          0.0|\n",
            "|       0|     3|35.0|   8.05|     0.0|          0.0|\n",
            "+--------+------+----+-------+--------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorAssembler = VectorAssembler(inputCols=[\"Pclass\", \"Age\", \"Fare\", \"SexIndex\", \"EmbarkedIndex\"], outputCol = \"features\")"
      ],
      "metadata": {
        "id": "4hhUoN10GLSc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
        "pipeline = Pipeline(stages=[vectorAssembler, scaler])\n",
        "scalerModel = pipeline.fit(df)\n",
        "scaledData = scalerModel.transform(df)\n",
        "scaledData.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMnPuU-TFb8x",
        "outputId": "b662e9e8-866c-4d87-e726-26e000ef582f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----+-------+--------+-------------+--------------------+--------------------+\n",
            "|Survived|Pclass| Age|   Fare|SexIndex|EmbarkedIndex|            features|     features_scaled|\n",
            "+--------+------+----+-------+--------+-------------+--------------------+--------------------+\n",
            "|       0|     3|22.0|   7.25|     0.0|          0.0|[3.0,22.0,7.25,0....|[1.0,0.2711736617...|\n",
            "|       1|     1|38.0|71.2833|     1.0|          1.0|[1.0,38.0,71.2833...|[0.0,0.4722292033...|\n",
            "|       1|     3|26.0|  7.925|     1.0|          0.0|[3.0,26.0,7.925,1...|[1.0,0.3214375471...|\n",
            "|       1|     1|35.0|   53.1|     1.0|          0.0|[1.0,35.0,53.1,1....|[0.0,0.4345312892...|\n",
            "|       0|     3|35.0|   8.05|     0.0|          0.0|[3.0,35.0,8.05,0....|[1.0,0.4345312892...|\n",
            "|       0|     1|54.0|51.8625|     0.0|          0.0|[1.0,54.0,51.8625...|(5,[1,2],[0.67328...|\n",
            "|       0|     3| 2.0| 21.075|     0.0|          0.0|[3.0,2.0,21.075,0...|[1.0,0.0198542347...|\n",
            "|       1|     3|27.0|11.1333|     1.0|          0.0|[3.0,27.0,11.1333...|[1.0,0.3340035184...|\n",
            "|       1|     2|14.0|30.0708|     1.0|          1.0|[2.0,14.0,30.0708...|[0.5,0.1706458909...|\n",
            "|       1|     3| 4.0|   16.7|     1.0|          0.0|[3.0,4.0,16.7,1.0...|[1.0,0.0449861774...|\n",
            "|       1|     1|58.0|  26.55|     1.0|          0.0|[1.0,58.0,26.55,1...|[0.0,0.7235486303...|\n",
            "|       0|     3|20.0|   8.05|     0.0|          0.0|[3.0,20.0,8.05,0....|[1.0,0.2460417190...|\n",
            "|       0|     3|39.0| 31.275|     0.0|          0.0|[3.0,39.0,31.275,...|[1.0,0.4847951746...|\n",
            "|       0|     3|14.0| 7.8542|     1.0|          0.0|[3.0,14.0,7.8542,...|[1.0,0.1706458909...|\n",
            "|       1|     2|55.0|   16.0|     1.0|          0.0|[2.0,55.0,16.0,1....|[0.5,0.6858507162...|\n",
            "|       0|     3| 2.0| 29.125|     0.0|          2.0|[3.0,2.0,29.125,0...|[1.0,0.0198542347...|\n",
            "|       0|     3|31.0|   18.0|     1.0|          0.0|[3.0,31.0,18.0,1....|[1.0,0.3842674038...|\n",
            "|       0|     2|35.0|   26.0|     0.0|          0.0|[2.0,35.0,26.0,0....|[0.5,0.4345312892...|\n",
            "|       1|     2|34.0|   13.0|     0.0|          0.0|[2.0,34.0,13.0,0....|[0.5,0.4219653179...|\n",
            "|       1|     3|15.0| 8.0292|     1.0|          2.0|[3.0,15.0,8.0292,...|[1.0,0.1832118622...|\n",
            "+--------+------+----+-------+--------+-------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = scaledData.randomSplit([0.8, 0.2], seed=23)"
      ],
      "metadata": {
        "id": "xXaKI5jDG-tE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "NklEzRn0HhJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"Survived\",\n",
        "featuresCol=\"features_scaled\")\n",
        "model = dt.fit(train_data)"
      ],
      "metadata": {
        "id": "eGTpG92xHI8y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6AAbPxgHPFZ",
        "outputId": "004f1fb1-a677-43c1-81d0-b47c07af0323"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron Multicapa"
      ],
      "metadata": {
        "id": "jmDQTEl0HisW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlpc=MultilayerPerceptronClassifier( featuresCol=\"features_scaled\",labelCol=\"Survived\" ,layers = [5,16,2], maxIter=1000,blockSize=8,seed=7,solver=\"gd\")"
      ],
      "metadata": {
        "id": "pz8oLktKHz9C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = mlpc.fit(train_data)"
      ],
      "metadata": {
        "id": "g9DPggViH6mN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = ann.transform(test_data)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol='prediction',metricName='accuracy')\n",
        "accuracy_ann = evaluator.evaluate(pred)\n",
        "print(f\"Test Accuracy: {accuracy_ann}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC9B8xjwH8Uq",
        "outputId": "0ceb6b1b-111f-407e-e686-135313cd082e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7931034482758621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "01OfoFXmIWkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"Survived\",\n",
        "featuresCol=\"features_scaled\"\n",
        ", numTrees=30)\n",
        "model = rf.fit(train_data)\n",
        "\n",
        "predictions = model.transform(test_data)"
      ],
      "metadata": {
        "id": "BLamDUxjIpEk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9ouTwtAJJDU",
        "outputId": "3b0c7855-9db4-4a18-e75e-ace93cde7c0f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7931034482758621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "AbRx9U1aJbkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(labelCol=\"Survived\",\n",
        "featuresCol=\"features_scaled\")\n",
        "nbmodel = nb.fit(train_data)"
      ],
      "metadata": {
        "id": "E8W3ZNyoJxqs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = nbmodel.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_nb = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy:{accuracy_nb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjFB4xEOKk_v",
        "outputId": "29b64ac5-8c88-4304-97d8-f0c906a1546f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.7931034482758621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística"
      ],
      "metadata": {
        "id": "Qvmey6UiK717"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "logistic_regression = LogisticRegression(featuresCol=\"features_scaled\"\n",
        ",labelCol=\"Survived\")\n",
        "model = logistic_regression.fit(train_data)"
      ],
      "metadata": {
        "id": "ylAC_8qfLDYy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_lr = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy:{accuracy_lr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM6Wn5VpLSvY",
        "outputId": "5626814c-5363-4270-b1ff-80a499bac19e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.8137931034482758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradiente-boosted Tree"
      ],
      "metadata": {
        "id": "PHEbi1zZLjBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt = GBTClassifier(labelCol=\"Survived\"\n",
        ",featuresCol=\"features_scaled\"\n",
        ", maxIter=10)\n",
        "model = gbt.fit(train_data)"
      ],
      "metadata": {
        "id": "Xmw8o99ULqyd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_gb = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy:{accuracy_gb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi4hPOsYMMck",
        "outputId": "abfac1fe-a396-4daa-b6d3-0b4fa220cfce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine"
      ],
      "metadata": {
        "id": "Fwn1QKcrMPhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "lsvc = LinearSVC(labelCol=\"Survived\"\n",
        ",featuresCol=\"features_scaled\"\n",
        ",maxIter=10)\n",
        "lsvcModel = lsvc.fit(train_data)"
      ],
      "metadata": {
        "id": "jTgCX62GMTKS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lsvcModel.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_lsvc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy:{accuracy_lsvc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QfP-VaCMawt",
        "outputId": "ac2b7df7-4d3f-427f-859d-9abb658b3869"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.8\n"
          ]
        }
      ]
    }
  ]
}